<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriately as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="MiniCache: KV Cache Compression in Depth Dimension for Large Language Models. Learn about an efficient compression strategy for LLMs."/>
    <meta property="og:title" content="MiniCache: Efficient KV Cache Compression for LLMs"/>
    <meta property="og:description" content="Discover MiniCache, a novel approach for compressing KV cache states in large language models, reducing memory footprint while maintaining performance."/>
    <meta property="og:url" content="https://yourwebsite.com"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X630-->
<!--    <meta property="og:image" content="static/images/minicache_banner.png"/>-->
<!--    <meta property="og:image:width" content="1200"/>-->
<!--    <meta property="og:image:height" content="630"/>-->

    <meta name="twitter:title" content="MiniCache: KV Cache Compression in Depth Dimension"/>
    <meta name="twitter:description" content="Explore how MiniCache compresses KV cache states to improve LLM efficiency, reducing memory and boosting performance."/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X600-->
<!--    <meta name="twitter:image" content="static/images/minicache_twitter_banner.png"/>-->
<!--    <meta name="twitter:card" content="summary_large_image"/>-->
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="MiniCache, KV Cache Compression, Large Language Models, LLM Inference, Memory Footprint, AI, NLP"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>


    <title>Motion Mamba</title>
    <link rel="icon" type="image/x-icon" href="static/images/run.svg">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">MiniCache: KV Cache Compression in Depth Dimension for
                        Large Language Models</h1>
                    <div class="is-size-5 publication-authors">

                        <span class="author-block">
                  <a href="https://www.linkedin.com/in/akideliu/" target="_blank">Akide Liu</a><sup>1</sup>,
                        </span>

                        <span class="author-block">
                  <a href="https://jing-liu.com/" target="_blank">
                      Jing Liu
                  </a><sup>1</sup>,
                        </span>

                        <span class="author-block">
                  <a href="https://zizhengpan.github.io/" target="_blank">
                        Zizheng Pan
                  </a><sup>1</sup>,
                        </span>

                        <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=CTEQwwwAAAAJ&hl=zh-CN" target="_blank">
                        Yefei He
                  </a><sup>2</sup>,
                        </span>

                        <span class="author-block">
                  <a href="https://research.monash.edu/en/persons/reza-haffari" target="_blank">
                        Reza Haffari
                  </a><sup>1</sup>,
                        </span>

                        <span class="author-block">
                        <a href="https://bohanzhuang.github.io/"
                           target="_blank">Bohan Zhuang</a><sup>1,2</sup><sup>✉</sup>,</span>
                    </div>
                    <p style="height: 10px;">&nbsp;</p>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><font size="4"><sup>1</sup> <a href="https://ziplab.github.io/"
                                                                                  target="_blank">ZIP Lab, Monash University</a></font></span>
                        <span class="author-block"><font size="4"><sup>2</sup> <a href="https://ziplab.github.io/"
                                                                                  target="_blank">ZIP Lab, ZheJiang University</a></font></span>
                        <p style="height: 10px;">&nbsp;</p>
                        <!--                        <span class="author-block"><font size="5"><a href="https://eccv2024.ecva.net/"-->
                        <!--                                                                     target="_blank"><b style="color: OrangeRed;">ECCV 2024</b></a></font></span><br>-->
                        <!--                        <span class="eql-cntrb"><small><sup>*</sup>Equal Contribution.</small></span>-->
                        <span class="eql-cntrb"><small><sup>✉</sup>Corresponding author.</small></span><br>
                        <!--                        <span class="eql-cntrb"><small><sup>†</sup>Work done while being a research assistant at Monash University.</small></span>-->
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- Paper link -->
                            <!-- <span class="link-block">
                              <a href="https://conference.pdf" target="_blank"
                              class="external-link button is-normal is-rounded is-dark">
                              <span class="icon">
                                <i class="fas fa-file-pdf"></i>
                              </span>
                              <span>Paper</span>
                            </a>
                          </span> -->

                            <!-- Supplementary link -->
                            <!-- <span class="link-block">
                              <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                              class="external-link button is-normal is-rounded is-dark">
                              <span class="icon">
                                <i class="fas fa-file-pdf"></i>
                              </span>
                              <span>Supplementary</span>
                            </a>
                          </span> -->

                            <!-- ArXiv Link -->
                            <span class="link-block">
                  <a href="https://arxiv.org/abs/2405.14366" target="_blank"
                     class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                            <!-- Github link -->
                            <span class="link-block">
                    <a href="https://github.com/AkideLiu/MiniCache" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                            <!-- Hugging Face Link -->
                            <span class="link-block">
                    <a href="https://huggingface.co/papers/2405.14366" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <img src="static/images/hfbw.svg" style="width: 70%;">
                    </span>
                    <span>Hugging Face</span>
                  </a>
                </span>

                            <!-- Citation Link -->
                            <span class="link-block">
                  <a href="static/scholar.html" target="_blank"
                     class="external-link button is-normal is-rounded is-dark">
                  <span>BibTeX</span>
                </a>
              </span>


                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<div class="news">
    <h2><font size="4"> <b>News:</b> </font></h2>
    <ul>
        <li><b>(05/23/2024)</b> &#127881; First version of the paper is released on <a
                href="https://arxiv.org/abs/2405.14366">arXiv.</a></li>
        </li>
    </ul>
</div>

<p style="height: 50px;">&nbsp;</p>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        A critical approach for efficiently deploying computationally demanding large language models
                        (LLMs) is Key-Value (KV) caching. The KV cache stores key-value states of previously generated
                        tokens, significantly reducing the need for repetitive computations and thereby lowering latency
                        in autoregressive generation. However, the size of the KV cache grows linearly with sequence
                        length, posing challenges for applications requiring long context input and extensive sequence
                        generation. In this paper, we present a simple yet effective approach, called MiniCache, to
                        compress the KV cache across layers from a novel depth perspective, significantly reducing the
                        memory footprint for LLM inference. Our approach is based on the observation that KV cache
                        states exhibit high similarity between the adjacent layers in the middle-to-deep portion of
                        LLMs. To facilitate merging, we propose disentangling the states into the magnitude and
                        direction components, interpolating the directions of the state vectors while preserving their
                        lengths unchanged. Furthermore, we introduce a token retention strategy to keep highly distinct
                        state pairs unmerged, thus preserving the information with minimal additional storage overhead.
                        Our MiniCache is training-free and general, complementing existing KV cache compression
                        strategies, such as quantization and sparsity. We conduct a comprehensive evaluation of
                        MiniCache utilizing various models including LLaMA-2, LLaMA-3, Phi-3, Mistral, and Mixtral
                        across multiple benchmarks, demonstrating its exceptional performance in achieving superior
                        compression ratios and high throughput. On the ShareGPT dataset, LLaMA-2-7B with 4-bit MiniCache
                        achieves a remarkable compression ratio of up to 5.02x, enhances inference throughput by
                        approximately 5x, and reduces the memory footprint by 41% compared to the FP16 full cache
                        baseline, all while maintaining near-lossless performance.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->


<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h2 class="title is-3">Observation</h2>
        </div>
    </div>

    <p style="height: 30px;">&nbsp;</p>

    <div class="image-container">
        <center>


            <!--            <img src="static/images/compare.svg" style="width: 50%;">-->
            <img src="static/images/CLKV_main_crop_x.jpg" style="width: 70%;"/>
            <div class="image-description" style="width: 70%">
                <p style="height: 10px;">&nbsp;</p><br>
                <p>
                    Overview of our MiniCache strategy and example results:
                    (a) shows the observation that the KV cache states between two adjacent layers are highly similar,
                    particularly across the middle to deep layers. The x-axis uses index/2 to represent the similarities
                    for
                    each pair of layers. (b) compares the performance of MiniCache, and the mean baseline, which simply
                    averages
                    the KV caches of two layers, using the LLaMA-3-70B model on the GSM8K
                    dataset. MiniCache, which begins merging from the half-layer depth, achieves
                    near-lossless performance.
                    (c) highlights the primary difference between MiniCache and previous approaches. MiniCache
                    investigates
                    the
                    inter-layer redundancy of KV caches along the depth dimension of LLMs, an aspect overlooked by
                    intra-layer-based methods. Here,
                    <em>T</em> refers to the last timestamp of pre-filling, and <em>T+1</em> des to the first timestamp
                    of decoding.
                </p><br>
            </div>

            <p style="height: 50px;">&nbsp;</p>

        </center>
    </div>

    <div class="image-container">
        <center>


            <!--            <img src="static/images/compare.svg" style="width: 50%;">-->
            <img src="static/images/Figure2.png" style="width: 70%;"/>
            <div class="image-description" style="width: 70%">
                <p style="height: 10px;">&nbsp;</p><br>
                <p>Overall of our explorations and observations : (a) shows the strong baseline by performing average
                    merging on the KV cache. (b) shows the pairwise similarity of cache states between adjacent layers.
                    (c) compares the MiniCache, simple average, and full cache baseline across five different
                    datasets.</p><br>
            </div>

            <p style="height: 50px;">&nbsp;</p>

        </center>
    </div>


    <p style="height: 30px;">&nbsp;</p>

</section>
<!-- End video carousel -->


<section class="section hero is-light">
    <div class="my-hero-body">
        <div class="container">
            <h2 class="title is-3">Methodology</h2>
        </div>

        <p style="height: 50px;">&nbsp;</p>

        <div class="image-container">
            <center>


                <!--            <img src="static/images/compare.svg" style="width: 50%;">-->
                <img src="static/images/CLKV_method_crop_v2.jpg" style="width: 70%;"/>
                <div class="image-description" style="width: 70%">
                    <p style="height: 10px;">&nbsp;</p><br>

                    <p>The illustration of the proposed method <strong>MiniCache</strong>. (a) depicts the cross-layer
                        compression process. We fetch the KV caches, from layers <em>l</em> and <em>l-1</em>, and merge
                        them into shared states via Eq.~(3). Additionally, we compute the &#8466;<sub>2</sub> norm for
                        the caches to obtain their magnitudes. Furthermore, we select unmergable tokens for retention,
                        then store merged cache, retention tokens, and magnitudes at layer <em>l</em> in
                        <strong>C</strong>. (b) illustrates the restoration process for layers <em>l</em> and
                        <em>l-1</em>, which includes magnitude rescaling in Eq.~(2) and retention token recovery.</p>
                    <br>
                </div>

                <p style="height: 50px;">&nbsp;</p>

            </center>
        </div>


    </div>
</section>

<section class="section hero is-small">
    <div class="my-hero-body">
        <div class="container">
            <h2 class="title is-3">Performance</h2>
        </div>

        <p style="height: 50px;">&nbsp;</p>

        <div class="image-container">
            <center>


                <!--            <img src="static/images/compare.svg" style="width: 50%;">-->
                <img src="static/images/main_exps_crop.jpg" style="width: 70%;"/>
                <div class="image-description" style="width: 70%">
                    <p style="height: 10px;">&nbsp;</p><br>

                    <p>Performance comparisons between our proposed MiniCache with the “averaging baseline” and the
                        “unmerged full cache baseline” on multiple datasets with Phi3-Mini, Mixtral-8x7B, LLaMA-3-8B,
                        and LLaMA-3-70B. More result details are shown in <a href="#sec:detailed_expriments_results">Section
                            4</a>. The x-axis indicates the number of layers merged. As more layers are merged, a
                        greater reduction in memory usage is achieved.</p>
                    <br>
                </div>

            </center>
        </div>


        <div class="image-container">
            <center>


                <!--            <img src="static/images/compare.svg" style="width: 50%;">-->
                <img src="static/images/longbench.png" style="width: 70%;"/>
                <div class="image-description" style="width: 70%">
                    <p style="height: 10px;">&nbsp;</p><br>

                    <p>Evaluation of different KV cache compression methods on LongBench.
                        MiniCache builds on top of 4-bit KIVI and achieves the best performance with the strongest
                        compression rate.</p>
                    <br>
                </div>

            </center>
        </div>


    </div>
</section>


<section class="section hero is-light">
    <div class="my-hero-body">
        <div class="container">
            <h2 class="title is-3">Algorithm</h2>
        </div>

        <p style="height: 50px;">&nbsp;</p>

        <div class="image-container">
            <center>


                <!--            <img src="static/images/compare.svg" style="width: 50%;">-->
                <img src="static/images/CLKV_Algorithm.jpg" style="width: 70%;"/>
                <div class="image-description" style="width: 70%">
                    <p style="height: 10px;">&nbsp;</p><br>

                    <p>Overall prefilling and decoding logic for <strong>MiniCache</strong> involves performing
                        cross-layer merging and recovery within our framework.</p>
                    <br>
                </div>

            </center>
        </div>





    </div>
</section>


<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>
@article{liu2024minicache,
  title={MiniCache: KV Cache Compression in Depth Dimension for Large Language Models},
  author={Liu, Akide and Liu, Jing and Pan, Zizheng and He, Yefei and Haffari, Gholamreza and Zhuang, Bohan},
  journal={arXiv preprint arXiv:2405.14366},
  year={2024}
}
        </code></pre>
    </div>
</section>
<!--End BibTex citation -->

<!-- 
  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

</body>
</html>
